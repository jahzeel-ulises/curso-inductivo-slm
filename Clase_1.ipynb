{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db6759f",
   "metadata": {},
   "source": [
    "# Clase 1: Del texto al vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db839957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883b829",
   "metadata": {},
   "source": [
    "## Extracci贸n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17353e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b90bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos.\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "texts = data.data\n",
    "labels = data.target\n",
    "target_names = data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot general para los datos\n",
    "def plot_representation(data_2d, labels, title):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for label_idx in range(len(categories)):\n",
    "        indices = np.where(labels == label_idx)\n",
    "        plt.scatter(data_2d[indices, 0], data_2d[indices, 1], \n",
    "                    label=target_names[label_idx], alpha=0.7, edgecolors='w')\n",
    "    \n",
    "    plt.title(f\"Representaci贸n: {title}\", fontsize=14)\n",
    "    plt.xlabel(\"Dimensi贸n Latente 1\")\n",
    "    plt.ylabel(\"Dimensi贸n Latente 2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd3c7b",
   "metadata": {},
   "source": [
    "## Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_matrix = bow_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca23e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_2d = TruncatedSVD(n_components=2).fit_transform(bow_matrix)\n",
    "bow_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_representation(bow_2d,labels,\"Bag of words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d824f9",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f66ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_2d = TruncatedSVD(n_components=2).fit_transform(tfidf_matrix)\n",
    "tfidf_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf880b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_representation(tfidf_2d,labels,\"Representacion: TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f1f46",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es practicamente lo que hicimos arriba\n",
    "lsa_model = TruncatedSVD(n_components=100)\n",
    "lsa_low_dim = lsa_model.fit_transform(tfidf_matrix)\n",
    "lsa_2d = TruncatedSVD(n_components=2).fit_transform(lsa_low_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec3f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_representation(lsa_2d,labels,\"Representacion: TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a0dea",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizacion de texto\n",
    "nltk.download('punkt')\n",
    "tokenized_texts = [word_tokenize(doc.lower()) for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector(w2v_model,tokens):\n",
    "    vecs = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=512, window=5, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_matrix = np.array([get_doc_vector(w2v_model,t) for t in tokenized_texts])\n",
    "w2v_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73829cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_2d = TruncatedSVD(n_components=2).fit_transform(w2v_matrix)\n",
    "w2v_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_representation(w2v_2d,labels,\"Representacion: W2V\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
